{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caderno de Testes - Sistema Unificado Inove AI Framework\n",
    "\n",
    "Testa a compatibilidade e funcionamento do sistema unificado para os 3 modelos:\n",
    "- **Claude Code** (via `CLAUDE.md`)\n",
    "- **Codex CLI** (via `AGENTS.md`)\n",
    "- **Antigravity/Gemini** (via `GEMINI.md`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: ajusta o path para a raiz do projeto\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from unittest.mock import patch\n",
    "\n",
    "# Navega para a raiz do projeto\n",
    "PROJECT_ROOT = Path(os.path.abspath('')).parent\n",
    "if PROJECT_ROOT.name == 'inove-ai-framework':\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "elif Path.cwd().name == 'tests':\n",
    "    os.chdir(Path.cwd().parent)\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "print(f\"Diretorio do projeto: {PROJECT_ROOT}\")\n",
    "\n",
    "# Adiciona scripts ao path\n",
    "sys.path.insert(0, str(PROJECT_ROOT / '.agents' / 'scripts'))\n",
    "\n",
    "# Contadores de teste\n",
    "PASSED = 0\n",
    "FAILED = 0\n",
    "SKIPPED = 0\n",
    "\n",
    "def assert_test(condition, name, detail=\"\"):\n",
    "    \"\"\"Helper para assercoes de teste.\"\"\"\n",
    "    global PASSED, FAILED\n",
    "    if condition:\n",
    "        PASSED += 1\n",
    "        print(f\"  PASS: {name}\")\n",
    "    else:\n",
    "        FAILED += 1\n",
    "        msg = f\"  FAIL: {name}\"\n",
    "        if detail:\n",
    "            msg += f\" ({detail})\"\n",
    "        print(msg)\n",
    "\n",
    "def skip_test(name, reason):\n",
    "    \"\"\"Marca teste como pulado.\"\"\"\n",
    "    global SKIPPED\n",
    "    SKIPPED += 1\n",
    "    print(f\"  SKIP: {name} - {reason}\")\n",
    "\n",
    "def section(title):\n",
    "    \"\"\"Imprime cabecalho de secao.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\" {title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "print(\"Setup concluido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Estrutura de Arquivos Bridge\n",
    "\n",
    "Verifica se os arquivos bridge (CLAUDE.md, AGENTS.md, GEMINI.md) existem e apontam para o sistema canonico `.agents/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"1. ARQUIVOS BRIDGE\")\n",
    "\n",
    "# 1.1 Existencia dos bridges\n",
    "bridge_files = {\n",
    "    \"CLAUDE.md\": \"Claude Code\",\n",
    "    \"AGENTS.md\": \"Codex CLI\",\n",
    "    \"GEMINI.md\": \"Antigravity/Gemini\",\n",
    "}\n",
    "\n",
    "for filename, platform in bridge_files.items():\n",
    "    filepath = PROJECT_ROOT / filename\n",
    "    assert_test(filepath.exists(), f\"{filename} existe ({platform})\")\n",
    "\n",
    "# 1.2 Bridges referenciam .agents/\n",
    "for filename, platform in bridge_files.items():\n",
    "    filepath = PROJECT_ROOT / filename\n",
    "    if filepath.exists():\n",
    "        content = filepath.read_text(encoding='utf-8')\n",
    "        has_ref = '.agents/' in content or '.agents\\\\' in content\n",
    "        assert_test(has_ref, f\"{filename} referencia .agents/ ({platform})\")\n",
    "    else:\n",
    "        skip_test(f\"{filename} referencia .agents/\", \"arquivo nao encontrado\")\n",
    "\n",
    "# 1.3 Instrucoes canonicas existem\n",
    "instructions = PROJECT_ROOT / '.agents' / 'INSTRUCTIONS.md'\n",
    "assert_test(instructions.exists(), \".agents/INSTRUCTIONS.md existe (fonte canonica)\")\n",
    "\n",
    "# 1.4 Arquitetura documentada\n",
    "architecture = PROJECT_ROOT / '.agents' / 'ARCHITECTURE.md'\n",
    "assert_test(architecture.exists(), \".agents/ARCHITECTURE.md existe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estrutura do Diretorio `.agents/`\n",
    "\n",
    "Valida que todos os subdiretorios obrigatorios existem e contem arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"2. ESTRUTURA .agents/\")\n",
    "\n",
    "agents_root = PROJECT_ROOT / '.agents'\n",
    "\n",
    "# 2.1 Subdiretorios obrigatorios\n",
    "required_dirs = ['agents', 'skills', 'workflows', 'scripts', 'config']\n",
    "for d in required_dirs:\n",
    "    dirpath = agents_root / d\n",
    "    assert_test(dirpath.exists() and dirpath.is_dir(), f\".agents/{d}/ existe\")\n",
    "\n",
    "# 2.2 Quantidade minima de agentes (esperado: 20)\n",
    "agents_dir = agents_root / 'agents'\n",
    "if agents_dir.exists():\n",
    "    agent_files = list(agents_dir.glob('*.md'))\n",
    "    assert_test(len(agent_files) >= 15, f\"Agentes suficientes: {len(agent_files)} encontrados (min 15)\")\n",
    "    print(f\"  INFO: Agentes encontrados: {[f.stem for f in sorted(agent_files)]}\")\n",
    "else:\n",
    "    skip_test(\"Contagem de agentes\", \".agents/agents/ nao encontrado\")\n",
    "\n",
    "# 2.3 Quantidade minima de skills (esperado: 36)\n",
    "skills_dir = agents_root / 'skills'\n",
    "if skills_dir.exists():\n",
    "    skill_dirs = [d for d in skills_dir.iterdir() if d.is_dir()]\n",
    "    skill_files = list(skills_dir.glob('*.md'))  # skills avulsas\n",
    "    total_skills = len(skill_dirs) + len(skill_files)\n",
    "    assert_test(total_skills >= 20, f\"Skills suficientes: {total_skills} encontradas (min 20)\")\n",
    "else:\n",
    "    skip_test(\"Contagem de skills\", \".agents/skills/ nao encontrado\")\n",
    "\n",
    "# 2.4 Quantidade minima de workflows (esperado: 18)\n",
    "workflows_dir = agents_root / 'workflows'\n",
    "if workflows_dir.exists():\n",
    "    workflow_files = list(workflows_dir.glob('*.md'))\n",
    "    assert_test(len(workflow_files) >= 10, f\"Workflows suficientes: {len(workflow_files)} encontrados (min 10)\")\n",
    "else:\n",
    "    skip_test(\"Contagem de workflows\", \".agents/workflows/ nao encontrado\")\n",
    "\n",
    "# 2.5 Scripts obrigatorios\n",
    "required_scripts = [\n",
    "    'platform_compat.py',\n",
    "    'lock_manager.py',\n",
    "    'auto_session.py',\n",
    "    'finish_task.py',\n",
    "    'progress_tracker.py',\n",
    "    'dashboard.py',\n",
    "    'sync_tracker.py',\n",
    "    'session_logger.py',\n",
    "    'metrics.py',\n",
    "]\n",
    "\n",
    "scripts_dir = agents_root / 'scripts'\n",
    "for script in required_scripts:\n",
    "    script_path = scripts_dir / script\n",
    "    assert_test(script_path.exists(), f\"Script {script} existe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Symlinks do Codex CLI (`.codex/`)\n",
    "\n",
    "Valida que os symlinks do Codex apontam corretamente para o sistema canonico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"3. CODEX CLI - SYMLINKS\")\n",
    "\n",
    "codex_dir = PROJECT_ROOT / '.codex'\n",
    "\n",
    "# 3.1 Diretorio .codex existe\n",
    "assert_test(codex_dir.exists(), \".codex/ diretorio existe\")\n",
    "\n",
    "if codex_dir.exists():\n",
    "    # 3.2 config.toml existe\n",
    "    codex_config = codex_dir / 'config.toml'\n",
    "    assert_test(codex_config.exists(), \".codex/config.toml existe\")\n",
    "\n",
    "    # 3.3 Symlink de skills\n",
    "    skills_link = codex_dir / 'skills'\n",
    "    if skills_link.exists():\n",
    "        is_symlink = skills_link.is_symlink()\n",
    "        assert_test(is_symlink, \".codex/skills e um symlink\")\n",
    "        if is_symlink:\n",
    "            target = os.readlink(skills_link)\n",
    "            assert_test(\n",
    "                '.agents/skills' in target or '../.agents/skills' in target,\n",
    "                f\".codex/skills aponta para .agents/skills (target: {target})\"\n",
    "            )\n",
    "            # Verifica se o symlink resolve corretamente\n",
    "            resolved = skills_link.resolve()\n",
    "            assert_test(resolved.exists(), \".codex/skills resolve para diretorio existente\")\n",
    "    else:\n",
    "        skip_test(\".codex/skills symlink\", \"nao encontrado\")\n",
    "\n",
    "    # 3.4 Symlink de prompts/workflows\n",
    "    prompts_link = codex_dir / 'prompts'\n",
    "    if prompts_link.exists():\n",
    "        is_symlink = prompts_link.is_symlink()\n",
    "        assert_test(is_symlink, \".codex/prompts e um symlink\")\n",
    "        if is_symlink:\n",
    "            target = os.readlink(prompts_link)\n",
    "            assert_test(\n",
    "                '.agents/workflows' in target or '../.agents/workflows' in target,\n",
    "                f\".codex/prompts aponta para .agents/workflows (target: {target})\"\n",
    "            )\n",
    "            resolved = prompts_link.resolve()\n",
    "            assert_test(resolved.exists(), \".codex/prompts resolve para diretorio existente\")\n",
    "    else:\n",
    "        skip_test(\".codex/prompts symlink\", \"nao encontrado\")\n",
    "\n",
    "    # 3.5 Conteudo acessivel via symlink == conteudo original\n",
    "    if skills_link.exists() and skills_link.is_symlink():\n",
    "        original_skills = set(f.name for f in (agents_root / 'skills').iterdir())\n",
    "        linked_skills = set(f.name for f in skills_link.iterdir())\n",
    "        assert_test(\n",
    "            original_skills == linked_skills,\n",
    "            f\"Skills via symlink identicas ao original ({len(original_skills)} items)\"\n",
    "        )\n",
    "else:\n",
    "    skip_test(\"Todos os testes Codex\", \".codex/ nao encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Platform Compat - Deteccao de Plataforma\n",
    "\n",
    "Testa o modulo `platform_compat.py` simulando cada plataforma via variaveis de ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"4. PLATFORM_COMPAT - DETECCAO DE PLATAFORMA\")\n",
    "\n",
    "# Reimporta para garantir estado limpo\n",
    "import importlib\n",
    "import platform_compat\n",
    "importlib.reload(platform_compat)\n",
    "\n",
    "# 4.1 get_agent_root() retorna Path valido\n",
    "root = platform_compat.get_agent_root()\n",
    "assert_test(isinstance(root, Path), f\"get_agent_root() retorna Path: {root}\")\n",
    "assert_test(root.exists(), f\"get_agent_root() aponta para diretorio existente\")\n",
    "\n",
    "# 4.2 Paths auxiliares\n",
    "assert_test(platform_compat.get_skills_path().exists(), \"get_skills_path() valido\")\n",
    "assert_test(platform_compat.get_agents_path().exists(), \"get_agents_path() valido\")\n",
    "assert_test(platform_compat.get_workflows_path().exists(), \"get_workflows_path() valido\")\n",
    "assert_test(platform_compat.get_scripts_path().exists(), \"get_scripts_path() valido\")\n",
    "\n",
    "# 4.3 Simular Claude Code\n",
    "env_clean = {k: v for k, v in os.environ.items()\n",
    "             if k not in ('CLAUDE_CODE_SESSION', 'CODEX_SESSION',\n",
    "                         'ANTIGRAVITY_SESSION', 'GEMINI_SESSION', 'AGENT_SOURCE')}\n",
    "\n",
    "with patch.dict(os.environ, {**env_clean, 'CLAUDE_CODE_SESSION': '1'}, clear=True):\n",
    "    importlib.reload(platform_compat)\n",
    "    result = platform_compat.get_agent_source()\n",
    "    assert_test(result == 'claude_code', f\"Claude Code detectado: {result}\")\n",
    "\n",
    "# 4.4 Simular Codex CLI\n",
    "with patch.dict(os.environ, {**env_clean, 'CODEX_SESSION': '1'}, clear=True):\n",
    "    importlib.reload(platform_compat)\n",
    "    result = platform_compat.get_agent_source()\n",
    "    assert_test(result == 'codex', f\"Codex CLI detectado: {result}\")\n",
    "\n",
    "# 4.5 Simular Antigravity via ANTIGRAVITY_SESSION\n",
    "with patch.dict(os.environ, {**env_clean, 'ANTIGRAVITY_SESSION': '1'}, clear=True):\n",
    "    importlib.reload(platform_compat)\n",
    "    result = platform_compat.get_agent_source()\n",
    "    assert_test(result == 'antigravity', f\"Antigravity (ANTIGRAVITY_SESSION) detectado: {result}\")\n",
    "\n",
    "# 4.6 Simular Antigravity via GEMINI_SESSION\n",
    "with patch.dict(os.environ, {**env_clean, 'GEMINI_SESSION': '1'}, clear=True):\n",
    "    importlib.reload(platform_compat)\n",
    "    result = platform_compat.get_agent_source()\n",
    "    assert_test(result == 'antigravity', f\"Antigravity (GEMINI_SESSION) detectado: {result}\")\n",
    "\n",
    "# 4.7 Simular AGENT_SOURCE explicito\n",
    "with patch.dict(os.environ, {**env_clean, 'AGENT_SOURCE': 'codex'}, clear=True):\n",
    "    importlib.reload(platform_compat)\n",
    "    result = platform_compat.get_agent_source()\n",
    "    assert_test(result == 'codex', f\"AGENT_SOURCE=codex fallback detectado: {result}\")\n",
    "\n",
    "# 4.8 Sem variavel de ambiente -> 'unknown'\n",
    "with patch.dict(os.environ, env_clean, clear=True):\n",
    "    importlib.reload(platform_compat)\n",
    "    result = platform_compat.get_agent_source()\n",
    "    assert_test(result == 'unknown', f\"Sem env vars -> unknown: {result}\")\n",
    "\n",
    "# 4.9 Prioridade: CODEX_SESSION > AGENT_SOURCE\n",
    "with patch.dict(os.environ, {**env_clean, 'CODEX_SESSION': '1', 'AGENT_SOURCE': 'antigravity'}, clear=True):\n",
    "    importlib.reload(platform_compat)\n",
    "    result = platform_compat.get_agent_source()\n",
    "    assert_test(result == 'codex', f\"Prioridade CODEX_SESSION > AGENT_SOURCE: {result}\")\n",
    "\n",
    "# 4.10 get_config_path() retorna path correto por plataforma\n",
    "importlib.reload(platform_compat)\n",
    "config_codex = platform_compat.get_config_path('codex')\n",
    "assert_test('codex.toml' in str(config_codex), f\"Config codex: {config_codex}\")\n",
    "\n",
    "config_claude = platform_compat.get_config_path('claude_code')\n",
    "assert_test('claude.json' in str(config_claude), f\"Config claude: {config_claude}\")\n",
    "\n",
    "config_anti = platform_compat.get_config_path('antigravity')\n",
    "assert_test('antigravity.json' in str(config_anti), f\"Config antigravity: {config_anti}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Lock Manager - Coordenacao Multi-Agent\n",
    "\n",
    "Testa acquire/release de locks, deteccao de stale locks, e conflitos entre agentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"5. LOCK MANAGER\")\n",
    "\n",
    "from lock_manager import LockManager\n",
    "\n",
    "# Usa diretorio temporario para nao afetar locks reais\n",
    "test_locks_dir = Path(tempfile.mkdtemp(prefix='inove_test_locks_'))\n",
    "lm = LockManager(locks_dir=test_locks_dir, default_timeout=5)\n",
    "\n",
    "try:\n",
    "    # 5.1 Acquire lock\n",
    "    result = lm.acquire_lock('backlog', 'claude_code')\n",
    "    assert_test(result == True, \"acquire_lock sucesso\")\n",
    "\n",
    "    # 5.2 Lock info disponivel\n",
    "    info = lm.get_lock_info('backlog')\n",
    "    assert_test(info is not None, \"get_lock_info retorna dados\")\n",
    "    assert_test(info['locked_by'] == 'claude_code', f\"Lock pertence a claude_code: {info.get('locked_by')}\")\n",
    "\n",
    "    # 5.3 Mesmo agente pode renovar lock\n",
    "    result = lm.acquire_lock('backlog', 'claude_code')\n",
    "    assert_test(result == True, \"Mesmo agente renova lock\")\n",
    "\n",
    "    # 5.4 Outro agente NAO pode adquirir lock ativo\n",
    "    result = lm.acquire_lock('backlog', 'antigravity')\n",
    "    assert_test(result == False, \"Agente diferente bloqueado\")\n",
    "\n",
    "    # 5.5 Release pelo dono\n",
    "    result = lm.release_lock('backlog', 'claude_code')\n",
    "    assert_test(result == True, \"Release pelo dono sucesso\")\n",
    "\n",
    "    # 5.6 Apos release, outro agente pode adquirir\n",
    "    result = lm.acquire_lock('backlog', 'antigravity')\n",
    "    assert_test(result == True, \"Antigravity adquire apos release\")\n",
    "\n",
    "    # 5.7 Release por agente errado falha\n",
    "    result = lm.release_lock('backlog', 'claude_code')\n",
    "    assert_test(result == False, \"Release por agente errado falha\")\n",
    "\n",
    "    # 5.8 Force release funciona\n",
    "    result = lm.force_release('backlog')\n",
    "    assert_test(result == True, \"Force release sucesso\")\n",
    "    info = lm.get_lock_info('backlog')\n",
    "    assert_test(info is None, \"Lock removido apos force release\")\n",
    "\n",
    "    # 5.9 Multiplos locks independentes\n",
    "    lm.acquire_lock('backlog', 'claude_code')\n",
    "    lm.acquire_lock('readme', 'antigravity')\n",
    "    lm.acquire_lock('config', 'codex')\n",
    "    active = lm.list_active_locks()\n",
    "    assert_test(len(active) == 3, f\"3 locks ativos simultaneos: {len(active)}\")\n",
    "    assert_test(active['backlog']['locked_by'] == 'claude_code', \"Backlog -> claude_code\")\n",
    "    assert_test(active['readme']['locked_by'] == 'antigravity', \"Readme -> antigravity\")\n",
    "    assert_test(active['config']['locked_by'] == 'codex', \"Config -> codex\")\n",
    "\n",
    "    # 5.10 Cleanup stale locks (timeout=5s, entao os locks ja devem estar validos)\n",
    "    count = lm.cleanup_stale_locks()\n",
    "    assert_test(count == 0, f\"Nenhum lock stale (timeout=5s): {count} removidos\")\n",
    "\n",
    "    # Limpa para o proximo teste\n",
    "    for r in ['backlog', 'readme', 'config']:\n",
    "        lm.force_release(r)\n",
    "\n",
    "    # 5.11 Deteccao de stale lock (simula lock expirado)\n",
    "    lock_file = test_locks_dir / 'stale_resource.lock'\n",
    "    stale_data = {\n",
    "        'locked_by': 'antigravity',\n",
    "        'locked_at': (datetime.now() - timedelta(seconds=600)).isoformat(),\n",
    "        'timeout': 5,\n",
    "        'pid': 99999\n",
    "    }\n",
    "    lock_file.write_text(json.dumps(stale_data))\n",
    "    info = lm.get_lock_info('stale_resource')\n",
    "    assert_test(info is None, \"Lock stale detectado e removido automaticamente\")\n",
    "\n",
    "    # 5.12 Lock com metadata extra\n",
    "    result = lm.acquire_lock('feature-x', 'claude_code', task='Epic-1', description='Auth')\n",
    "    assert_test(result == True, \"Lock com metadata adquirido\")\n",
    "    info = lm.get_lock_info('feature-x')\n",
    "    assert_test(info.get('task') == 'Epic-1', f\"Metadata 'task' preservada: {info.get('task')}\")\n",
    "    assert_test(info.get('description') == 'Auth', f\"Metadata 'description' preservada\")\n",
    "    lm.force_release('feature-x')\n",
    "\n",
    "    # 5.13 Release de recurso inexistente retorna True\n",
    "    result = lm.release_lock('nao_existe', 'claude_code')\n",
    "    assert_test(result == True, \"Release de recurso inexistente retorna True\")\n",
    "\n",
    "finally:\n",
    "    # Cleanup\n",
    "    shutil.rmtree(test_locks_dir, ignore_errors=True)\n",
    "    print(f\"  INFO: Diretorio temporario limpo: {test_locks_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Auto Session - Gerenciamento de Sessao\n",
    "\n",
    "Testa inicio, status e encerramento de sessoes para cada plataforma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"6. AUTO SESSION\")\n",
    "\n",
    "import auto_session\n",
    "importlib.reload(auto_session)\n",
    "\n",
    "# Salva estado original da sessao se existir\n",
    "original_session_file = Path('.agents/.session_state.json')\n",
    "original_session_backup = None\n",
    "if original_session_file.exists():\n",
    "    original_session_backup = original_session_file.read_text()\n",
    "\n",
    "try:\n",
    "    # Limpa sessao existente para testes\n",
    "    auto_session.clear_session()\n",
    "\n",
    "    # 6.1 Deteccao de agente - Claude Code\n",
    "    with patch.dict(os.environ, {'CLAUDE_CODE_SESSION': '1'}, clear=False):\n",
    "        result = auto_session.get_agent_source()\n",
    "        assert_test(result == 'claude_code', f\"Session detecta Claude Code: {result}\")\n",
    "\n",
    "    # 6.2 Deteccao de agente - Antigravity\n",
    "    env_clean_session = {k: v for k, v in os.environ.items()\n",
    "                        if k not in ('CLAUDE_CODE_SESSION', 'CODEX_SESSION',\n",
    "                                    'ANTIGRAVITY_SESSION', 'GEMINI_SESSION', 'AGENT_SOURCE')}\n",
    "    with patch.dict(os.environ, {**env_clean_session, 'GEMINI_SESSION': '1'}, clear=True):\n",
    "        result = auto_session.get_agent_source()\n",
    "        assert_test(result == 'antigravity', f\"Session detecta Antigravity: {result}\")\n",
    "\n",
    "    # 6.3 Iniciar sessao com override\n",
    "    auto_session.clear_session()\n",
    "    result = auto_session.start_session(agent_override='claude_code')\n",
    "    assert_test(result == True, \"Sessao iniciada com sucesso\")\n",
    "\n",
    "    # 6.4 Sessao salva corretamente\n",
    "    session = auto_session.load_session()\n",
    "    assert_test(session is not None, \"Sessao carregada do arquivo\")\n",
    "    assert_test(session['agent'] == 'claude_code', f\"Agente da sessao: {session.get('agent')}\")\n",
    "    assert_test(session['ended'] == False, \"Sessao nao encerrada\")\n",
    "    assert_test('start_time' in session, \"start_time presente\")\n",
    "    assert_test('date' in session, \"date presente\")\n",
    "    assert_test('project' in session, f\"project presente: {session.get('project')}\")\n",
    "\n",
    "    # 6.5 Nao pode iniciar sessao duplicada\n",
    "    result = auto_session.start_session(agent_override='antigravity')\n",
    "    assert_test(result == False, \"Sessao duplicada bloqueada\")\n",
    "\n",
    "    # 6.6 Encerrar sessao\n",
    "    result = auto_session.end_session(activities='Teste unitario; Validacao do sistema')\n",
    "    assert_test(result == True, \"Sessao encerrada com sucesso\")\n",
    "\n",
    "    # 6.7 Nao pode encerrar sessao ja encerrada\n",
    "    result = auto_session.end_session()\n",
    "    assert_test(result == False, \"Encerrar sessao ja encerrada falha\")\n",
    "\n",
    "    # 6.8 Iniciar sessao como Antigravity\n",
    "    result = auto_session.start_session(agent_override='antigravity')\n",
    "    assert_test(result == True, \"Sessao Antigravity iniciada\")\n",
    "    session = auto_session.load_session()\n",
    "    assert_test(session['agent'] == 'antigravity', \"Agente Antigravity correto\")\n",
    "\n",
    "    # 6.9 Encerrar e verificar limpeza\n",
    "    auto_session.end_session(quick=True)\n",
    "    session = auto_session.load_session()\n",
    "    assert_test(session is None, \"Sessao limpa apos encerramento\")\n",
    "\n",
    "    # 6.10 Iniciar sessao como Codex\n",
    "    result = auto_session.start_session(agent_override='codex')\n",
    "    assert_test(result == True, \"Sessao Codex iniciada\")\n",
    "    session = auto_session.load_session()\n",
    "    assert_test(session['agent'] == 'codex', \"Agente Codex correto\")\n",
    "    auto_session.end_session(quick=True)\n",
    "\n",
    "finally:\n",
    "    # Restaura sessao original\n",
    "    auto_session.clear_session()\n",
    "    if original_session_backup:\n",
    "        original_session_file.write_text(original_session_backup)\n",
    "        print(\"  INFO: Sessao original restaurada\")\n",
    "    else:\n",
    "        print(\"  INFO: Nenhuma sessao original para restaurar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Configuracoes por Plataforma\n",
    "\n",
    "Valida que os arquivos de configuracao existem e tem formato correto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"7. CONFIGURACOES POR PLATAFORMA\")\n",
    "\n",
    "config_dir = agents_root / 'config'\n",
    "\n",
    "# 7.1 codex.toml existe e e parseavel\n",
    "codex_toml = config_dir / 'codex.toml'\n",
    "if codex_toml.exists():\n",
    "    content = codex_toml.read_text()\n",
    "    assert_test(len(content) > 0, \"codex.toml tem conteudo\")\n",
    "    # Verifica campos basicos\n",
    "    assert_test('model' in content, \"codex.toml contem 'model'\")\n",
    "    assert_test('approval_policy' in content or 'sandbox' in content,\n",
    "                \"codex.toml contem politicas de aprovacao ou sandbox\")\n",
    "else:\n",
    "    skip_test(\"codex.toml\", \"arquivo nao encontrado\")\n",
    "\n",
    "# 7.2 mcp.json existe e e JSON valido\n",
    "mcp_json = config_dir / 'mcp.json'\n",
    "if mcp_json.exists():\n",
    "    try:\n",
    "        data = json.loads(mcp_json.read_text())\n",
    "        assert_test(isinstance(data, dict), \"mcp.json e JSON valido\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        assert_test(False, f\"mcp.json JSON invalido: {e}\")\n",
    "else:\n",
    "    skip_test(\"mcp.json\", \"arquivo nao encontrado\")\n",
    "\n",
    "# 7.3 Claude settings\n",
    "claude_settings = PROJECT_ROOT / '.claude' / 'settings.json'\n",
    "if claude_settings.exists():\n",
    "    try:\n",
    "        data = json.loads(claude_settings.read_text())\n",
    "        assert_test(isinstance(data, dict), \".claude/settings.json e JSON valido\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        assert_test(False, f\".claude/settings.json JSON invalido: {e}\")\n",
    "else:\n",
    "    skip_test(\".claude/settings.json\", \"arquivo nao encontrado\")\n",
    "\n",
    "# 7.4 Gemini rules\n",
    "gemini_rules = agents_root / 'rules' / 'GEMINI.md'\n",
    "if gemini_rules.exists():\n",
    "    content = gemini_rules.read_text()\n",
    "    assert_test(len(content) > 100, f\"GEMINI.md rules tem conteudo ({len(content)} chars)\")\n",
    "else:\n",
    "    skip_test(\"GEMINI.md rules\", \"arquivo nao encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Consistencia de Agentes\n",
    "\n",
    "Valida que todos os agentes tem a estrutura correta (frontmatter YAML + corpo markdown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"8. CONSISTENCIA DE AGENTES\")\n",
    "\n",
    "import re\n",
    "\n",
    "agents_dir = agents_root / 'agents'\n",
    "agent_files = sorted(agents_dir.glob('*.md')) if agents_dir.exists() else []\n",
    "\n",
    "expected_agents = [\n",
    "    'orchestrator', 'frontend-specialist', 'backend-specialist',\n",
    "    'database-architect', 'mobile-developer', 'security-auditor',\n",
    "    'debugger', 'devops-engineer', 'test-engineer', 'product-owner',\n",
    "    'qa-automation-engineer', 'documentation-writer', 'code-archaeologist',\n",
    "    'performance-optimizer', 'explorer-agent', 'project-planner',\n",
    "    'product-manager', 'seo-specialist', 'penetration-tester', 'game-developer',\n",
    "]\n",
    "\n",
    "# 8.1 Agentes esperados existem\n",
    "existing_stems = [f.stem for f in agent_files]\n",
    "for agent_name in expected_agents:\n",
    "    assert_test(agent_name in existing_stems, f\"Agente {agent_name} existe\")\n",
    "\n",
    "# 8.2 Cada agente tem frontmatter YAML valido\n",
    "frontmatter_pattern = re.compile(r'^---\\s*\\n(.+?)\\n---', re.DOTALL)\n",
    "\n",
    "for agent_file in agent_files:\n",
    "    content = agent_file.read_text(encoding='utf-8')\n",
    "    match = frontmatter_pattern.match(content)\n",
    "    has_fm = match is not None\n",
    "    assert_test(has_fm, f\"{agent_file.stem}: tem frontmatter YAML\")\n",
    "\n",
    "    if has_fm:\n",
    "        fm_text = match.group(1)\n",
    "        # Verifica campos obrigatorios\n",
    "        has_name = 'name:' in fm_text\n",
    "        has_desc = 'description:' in fm_text\n",
    "        if not has_name:\n",
    "            assert_test(False, f\"{agent_file.stem}: falta 'name' no frontmatter\")\n",
    "        if not has_desc:\n",
    "            assert_test(False, f\"{agent_file.stem}: falta 'description' no frontmatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Consistencia de Skills\n",
    "\n",
    "Verifica que skills referenciadas pelos agentes existem no diretorio de skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"9. CONSISTENCIA DE SKILLS\")\n",
    "\n",
    "skills_dir = agents_root / 'skills'\n",
    "\n",
    "# 9.1 Coletar todas as skills referenciadas nos agentes\n",
    "referenced_skills = set()\n",
    "for agent_file in agent_files:\n",
    "    content = agent_file.read_text(encoding='utf-8')\n",
    "    match = frontmatter_pattern.match(content)\n",
    "    if match:\n",
    "        fm_text = match.group(1)\n",
    "        skills_match = re.search(r'skills:\\s*(.+)', fm_text)\n",
    "        if skills_match:\n",
    "            skills_str = skills_match.group(1).strip()\n",
    "            # Pode ser lista YAML ou CSV\n",
    "            if skills_str.startswith('['):\n",
    "                skills_list = [s.strip().strip('\"').strip(\"'\") for s in skills_str.strip('[]').split(',')]\n",
    "            else:\n",
    "                skills_list = [s.strip() for s in skills_str.split(',')]\n",
    "            referenced_skills.update(s for s in skills_list if s)\n",
    "\n",
    "print(f\"  INFO: {len(referenced_skills)} skills referenciadas pelos agentes\")\n",
    "\n",
    "# 9.2 Verificar que cada skill referenciada existe\n",
    "available_skills = set()\n",
    "if skills_dir.exists():\n",
    "    for item in skills_dir.iterdir():\n",
    "        if item.is_dir():\n",
    "            available_skills.add(item.name)\n",
    "        elif item.suffix == '.md':\n",
    "            available_skills.add(item.stem)\n",
    "\n",
    "print(f\"  INFO: {len(available_skills)} skills disponiveis\")\n",
    "\n",
    "missing_skills = referenced_skills - available_skills\n",
    "for skill in sorted(referenced_skills):\n",
    "    if skill in available_skills:\n",
    "        assert_test(True, f\"Skill '{skill}' existe\")\n",
    "    else:\n",
    "        assert_test(False, f\"Skill '{skill}' referenciada mas NAO encontrada\")\n",
    "\n",
    "# 9.3 Skills com SKILL.md (index)\n",
    "skill_dirs_with_index = 0\n",
    "skill_dirs_total = 0\n",
    "for item in skills_dir.iterdir():\n",
    "    if item.is_dir() and not item.name.startswith('.'):\n",
    "        skill_dirs_total += 1\n",
    "        if (item / 'SKILL.md').exists():\n",
    "            skill_dirs_with_index += 1\n",
    "\n",
    "if skill_dirs_total > 0:\n",
    "    pct = skill_dirs_with_index / skill_dirs_total * 100\n",
    "    assert_test(pct >= 80, f\"{skill_dirs_with_index}/{skill_dirs_total} skill dirs tem SKILL.md ({pct:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Workflows Cross-Platform\n",
    "\n",
    "Verifica que os workflows sao acessiveis por todas as plataformas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"10. WORKFLOWS CROSS-PLATFORM\")\n",
    "\n",
    "workflows_dir = agents_root / 'workflows'\n",
    "\n",
    "expected_workflows = [\n",
    "    'define', 'brainstorm', 'create', 'debug', 'enhance',\n",
    "    'deploy', 'test', 'track', 'status', 'finish',\n",
    "    'context', 'readiness', 'journeys', 'log',\n",
    "]\n",
    "\n",
    "# 10.1 Workflows esperados existem\n",
    "if workflows_dir.exists():\n",
    "    existing_workflows = [f.stem for f in workflows_dir.glob('*.md')]\n",
    "    for wf_name in expected_workflows:\n",
    "        assert_test(wf_name in existing_workflows, f\"Workflow '{wf_name}' existe\")\n",
    "else:\n",
    "    skip_test(\"Workflows\", \"diretorio nao encontrado\")\n",
    "\n",
    "# 10.2 Workflows acessiveis via .codex/prompts (symlink)\n",
    "codex_prompts = PROJECT_ROOT / '.codex' / 'prompts'\n",
    "if codex_prompts.exists():\n",
    "    codex_workflows = [f.stem for f in codex_prompts.glob('*.md')]\n",
    "    for wf_name in expected_workflows:\n",
    "        assert_test(\n",
    "            wf_name in codex_workflows,\n",
    "            f\"Workflow '{wf_name}' acessivel via .codex/prompts\"\n",
    "        )\n",
    "else:\n",
    "    skip_test(\"Workflows via Codex\", \".codex/prompts nao encontrado\")\n",
    "\n",
    "# 10.3 Conteudo identico entre acesso direto e symlink\n",
    "if codex_prompts.exists() and workflows_dir.exists():\n",
    "    sample_wf = 'define.md'\n",
    "    direct = (workflows_dir / sample_wf)\n",
    "    via_symlink = (codex_prompts / sample_wf)\n",
    "    if direct.exists() and via_symlink.exists():\n",
    "        assert_test(\n",
    "            direct.read_text() == via_symlink.read_text(),\n",
    "            f\"Conteudo de '{sample_wf}' identico via acesso direto e symlink\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Deteccao de Agente nos Scripts\n",
    "\n",
    "Verifica que todos os scripts que usam deteccao de agente sao consistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"11. DETECCAO DE AGENTE CONSISTENTE\")\n",
    "\n",
    "scripts_dir = agents_root / 'scripts'\n",
    "scripts_with_detection = []\n",
    "\n",
    "for script_file in sorted(scripts_dir.glob('*.py')):\n",
    "    content = script_file.read_text(encoding='utf-8')\n",
    "    # Procura por funcoes de deteccao de agente\n",
    "    has_detection = any([\n",
    "        'get_agent_source' in content,\n",
    "        'AGENT_SOURCE' in content,\n",
    "        'CLAUDE_CODE_SESSION' in content,\n",
    "        'GEMINI_SESSION' in content,\n",
    "        'CODEX_SESSION' in content,\n",
    "    ])\n",
    "    if has_detection:\n",
    "        scripts_with_detection.append(script_file.name)\n",
    "\n",
    "print(f\"  INFO: {len(scripts_with_detection)} scripts com deteccao de agente\")\n",
    "\n",
    "# 11.1 Scripts criticos tem deteccao\n",
    "critical_scripts = ['lock_manager.py', 'auto_session.py', 'finish_task.py', 'platform_compat.py']\n",
    "for script in critical_scripts:\n",
    "    assert_test(\n",
    "        script in scripts_with_detection,\n",
    "        f\"{script} tem deteccao de agente\"\n",
    "    )\n",
    "\n",
    "# 11.2 Todos os scripts que detectam agente suportam os 3 modelos\n",
    "for script_name in scripts_with_detection:\n",
    "    content = (scripts_dir / script_name).read_text(encoding='utf-8')\n",
    "    supports_claude = 'claude_code' in content or 'CLAUDE_CODE_SESSION' in content\n",
    "    supports_gemini = 'antigravity' in content or 'GEMINI_SESSION' in content or 'ANTIGRAVITY_SESSION' in content\n",
    "    \n",
    "    # Pelo menos Claude e Antigravity devem ser suportados (Codex pode usar AGENT_SOURCE)\n",
    "    if supports_claude and supports_gemini:\n",
    "        assert_test(True, f\"{script_name}: suporta Claude + Antigravity\")\n",
    "    else:\n",
    "        missing = []\n",
    "        if not supports_claude:\n",
    "            missing.append('Claude Code')\n",
    "        if not supports_gemini:\n",
    "            missing.append('Antigravity')\n",
    "        assert_test(False, f\"{script_name}: falta suporte para {', '.join(missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Integracao End-to-End: Fluxo Completo por Plataforma\n",
    "\n",
    "Simula o fluxo completo de um agente em cada plataforma: deteccao -> sessao -> lock -> release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"12. INTEGRACAO E2E - FLUXO COMPLETO\")\n",
    "\n",
    "test_locks_dir_e2e = Path(tempfile.mkdtemp(prefix='inove_e2e_locks_'))\n",
    "original_session_backup_e2e = None\n",
    "if original_session_file.exists():\n",
    "    original_session_backup_e2e = original_session_file.read_text()\n",
    "\n",
    "platforms = [\n",
    "    ('claude_code', {'CLAUDE_CODE_SESSION': '1'}),\n",
    "    ('codex', {'CODEX_SESSION': '1'}),\n",
    "    ('antigravity', {'GEMINI_SESSION': '1'}),\n",
    "]\n",
    "\n",
    "try:\n",
    "    for platform_name, env_vars in platforms:\n",
    "        print(f\"\\n  --- Testando plataforma: {platform_name} ---\")\n",
    "\n",
    "        # Limpa estado\n",
    "        auto_session.clear_session()\n",
    "        lm_e2e = LockManager(locks_dir=test_locks_dir_e2e, default_timeout=60)\n",
    "        for f in test_locks_dir_e2e.glob('*.lock'):\n",
    "            f.unlink()\n",
    "\n",
    "        env_base = {k: v for k, v in os.environ.items()\n",
    "                    if k not in ('CLAUDE_CODE_SESSION', 'CODEX_SESSION',\n",
    "                                'ANTIGRAVITY_SESSION', 'GEMINI_SESSION', 'AGENT_SOURCE')}\n",
    "\n",
    "        with patch.dict(os.environ, {**env_base, **env_vars}, clear=True):\n",
    "            # Step 1: Deteccao de plataforma\n",
    "            importlib.reload(platform_compat)\n",
    "            detected = platform_compat.get_agent_source()\n",
    "            assert_test(\n",
    "                detected == platform_name,\n",
    "                f\"[{platform_name}] Plataforma detectada: {detected}\"\n",
    "            )\n",
    "\n",
    "            # Step 2: Paths resolvem corretamente\n",
    "            root = platform_compat.get_agent_root()\n",
    "            assert_test(root.exists(), f\"[{platform_name}] Agent root existe\")\n",
    "\n",
    "            # Step 3: Iniciar sessao\n",
    "            result = auto_session.start_session(agent_override=platform_name)\n",
    "            assert_test(result, f\"[{platform_name}] Sessao iniciada\")\n",
    "\n",
    "            # Step 4: Adquirir lock\n",
    "            result = lm_e2e.acquire_lock('backlog', platform_name)\n",
    "            assert_test(result, f\"[{platform_name}] Lock adquirido\")\n",
    "\n",
    "            # Step 5: Verificar lock info\n",
    "            info = lm_e2e.get_lock_info('backlog')\n",
    "            assert_test(\n",
    "                info and info['locked_by'] == platform_name,\n",
    "                f\"[{platform_name}] Lock pertence ao agente correto\"\n",
    "            )\n",
    "\n",
    "            # Step 6: Liberar lock\n",
    "            result = lm_e2e.release_lock('backlog', platform_name)\n",
    "            assert_test(result, f\"[{platform_name}] Lock liberado\")\n",
    "\n",
    "            # Step 7: Encerrar sessao\n",
    "            result = auto_session.end_session(quick=True)\n",
    "            assert_test(result, f\"[{platform_name}] Sessao encerrada\")\n",
    "\n",
    "    # Teste de conflito entre plataformas\n",
    "    print(f\"\\n  --- Teste de conflito multi-agent ---\")\n",
    "    for f in test_locks_dir_e2e.glob('*.lock'):\n",
    "        f.unlink()\n",
    "\n",
    "    lm_conflict = LockManager(locks_dir=test_locks_dir_e2e, default_timeout=60)\n",
    "\n",
    "    # Claude Code adquire lock\n",
    "    lm_conflict.acquire_lock('shared_resource', 'claude_code')\n",
    "\n",
    "    # Codex tenta adquirir o mesmo recurso\n",
    "    result = lm_conflict.acquire_lock('shared_resource', 'codex')\n",
    "    assert_test(result == False, \"Conflito: Codex bloqueado por Claude Code\")\n",
    "\n",
    "    # Antigravity tenta adquirir o mesmo recurso\n",
    "    result = lm_conflict.acquire_lock('shared_resource', 'antigravity')\n",
    "    assert_test(result == False, \"Conflito: Antigravity bloqueado por Claude Code\")\n",
    "\n",
    "    # Claude Code libera\n",
    "    lm_conflict.release_lock('shared_resource', 'claude_code')\n",
    "\n",
    "    # Agora Codex consegue\n",
    "    result = lm_conflict.acquire_lock('shared_resource', 'codex')\n",
    "    assert_test(result == True, \"Apos release: Codex adquire lock\")\n",
    "\n",
    "    # Antigravity ainda bloqueado\n",
    "    result = lm_conflict.acquire_lock('shared_resource', 'antigravity')\n",
    "    assert_test(result == False, \"Conflito: Antigravity bloqueado por Codex\")\n",
    "\n",
    "    lm_conflict.force_release('shared_resource')\n",
    "\n",
    "finally:\n",
    "    shutil.rmtree(test_locks_dir_e2e, ignore_errors=True)\n",
    "    auto_session.clear_session()\n",
    "    if original_session_backup_e2e:\n",
    "        original_session_file.write_text(original_session_backup_e2e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Validacao de Migracao\n",
    "\n",
    "Verifica que nao restam referencias ao sistema legado `.agent/` (sem 's')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"13. VALIDACAO DE MIGRACAO\")\n",
    "\n",
    "# 13.1 Diretorio legado .agent/ nao existe\n",
    "legacy_dir = PROJECT_ROOT / '.agent'\n",
    "assert_test(\n",
    "    not legacy_dir.exists(),\n",
    "    f\"Diretorio legado .agent/ NAO existe (migrado para .agents/)\"\n",
    ")\n",
    "\n",
    "# 13.2 Script de migracao existe\n",
    "migrate_script = PROJECT_ROOT / 'migrate_to_unified.py'\n",
    "assert_test(migrate_script.exists(), \"migrate_to_unified.py existe\")\n",
    "\n",
    "# 13.3 Bridges NAO contem path legado hardcoded\n",
    "for filename in ['CLAUDE.md', 'AGENTS.md', 'GEMINI.md']:\n",
    "    filepath = PROJECT_ROOT / filename\n",
    "    if filepath.exists():\n",
    "        content = filepath.read_text(encoding='utf-8')\n",
    "        # Procura por .agent/ (sem s) que NAO seja parte de .agents/\n",
    "        # Regex: .agent/ nao seguido de 's'\n",
    "        legacy_refs = re.findall(r'\\.agent/(?!s)', content)\n",
    "        assert_test(\n",
    "            len(legacy_refs) == 0,\n",
    "            f\"{filename}: sem referencias legadas .agent/ ({len(legacy_refs)} encontradas)\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 13.5 Symlinks Nativos do Claude Code (`.claude/`)\n\nValida que os symlinks nativos do Claude Code apontam para o sistema canonico `.agents/`.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "section(\"13.5 SYMLINKS NATIVOS - CLAUDE CODE E CODEX\")\n\n# --- Claude Code (.claude/) ---\nclaude_dir = PROJECT_ROOT / '.claude'\n\n# 13.5.1 .claude/agents e symlink\nclaude_agents = claude_dir / 'agents'\nif claude_agents.exists():\n    assert_test(claude_agents.is_symlink(), \".claude/agents e um symlink\")\n    if claude_agents.is_symlink():\n        target = os.readlink(claude_agents)\n        assert_test(\n            '.agents/agents' in target,\n            f\".claude/agents aponta para .agents/agents (target: {target})\"\n        )\n        assert_test(claude_agents.resolve().exists(), \".claude/agents resolve para diretorio existente\")\nelse:\n    skip_test(\".claude/agents\", \"nao encontrado\")\n\n# 13.5.2 .claude/skills e symlink\nclaude_skills = claude_dir / 'skills'\nif claude_skills.exists():\n    assert_test(claude_skills.is_symlink(), \".claude/skills e um symlink\")\n    if claude_skills.is_symlink():\n        target = os.readlink(claude_skills)\n        assert_test(\n            '.agents/skills' in target,\n            f\".claude/skills aponta para .agents/skills (target: {target})\"\n        )\n        assert_test(claude_skills.resolve().exists(), \".claude/skills resolve para diretorio existente\")\nelse:\n    skip_test(\".claude/skills\", \"nao encontrado\")\n\n# 13.5.3 Conteudo via .claude/agents == .agents/agents\nif claude_agents.exists() and claude_agents.is_symlink():\n    original = set(f.name for f in (agents_root / 'agents').iterdir() if f.suffix == '.md')\n    via_link = set(f.name for f in claude_agents.iterdir() if f.suffix == '.md')\n    assert_test(original == via_link, f\".claude/agents: conteudo identico ({len(original)} agentes)\")\n\n# 13.5.4 Conteudo via .claude/skills == .agents/skills\nif claude_skills.exists() and claude_skills.is_symlink():\n    original = set(f.name for f in (agents_root / 'skills').iterdir())\n    via_link = set(f.name for f in claude_skills.iterdir())\n    assert_test(original == via_link, f\".claude/skills: conteudo identico ({len(original)} skills)\")\n\n# --- Codex CLI (.codex/agents) ---\ncodex_agents = PROJECT_ROOT / '.codex' / 'agents'\nif codex_agents.exists():\n    assert_test(codex_agents.is_symlink(), \".codex/agents e um symlink\")\n    if codex_agents.is_symlink():\n        target = os.readlink(codex_agents)\n        assert_test(\n            '.agents/agents' in target,\n            f\".codex/agents aponta para .agents/agents (target: {target})\"\n        )\n        assert_test(codex_agents.resolve().exists(), \".codex/agents resolve para diretorio existente\")\n\n    # Conteudo identico\n    original = set(f.name for f in (agents_root / 'agents').iterdir() if f.suffix == '.md')\n    via_link = set(f.name for f in codex_agents.iterdir() if f.suffix == '.md')\n    assert_test(original == via_link, f\".codex/agents: conteudo identico ({len(original)} agentes)\")\nelse:\n    skip_test(\".codex/agents\", \"nao encontrado\")\n\n# --- Cross-check: todos os 3 acessos retornam o mesmo conteudo ---\nif all(p.exists() for p in [agents_root / 'agents', claude_agents, codex_agents]):\n    direct = set(f.name for f in (agents_root / 'agents').iterdir() if f.suffix == '.md')\n    via_claude = set(f.name for f in claude_agents.iterdir() if f.suffix == '.md')\n    via_codex = set(f.name for f in codex_agents.iterdir() if f.suffix == '.md')\n    assert_test(\n        direct == via_claude == via_codex,\n        f\"Cross-check: 3 plataformas veem os mesmos {len(direct)} agentes\"\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Resumo dos Testes\n",
    "\n",
    "Exibe o resultado consolidado de todos os testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"RESUMO FINAL\")\n",
    "\n",
    "total = PASSED + FAILED + SKIPPED\n",
    "pass_rate = (PASSED / total * 100) if total > 0 else 0\n",
    "\n",
    "print(f\"\")\n",
    "print(f\"  Total de testes:  {total}\")\n",
    "print(f\"  Passou:           {PASSED}\")\n",
    "print(f\"  Falhou:           {FAILED}\")\n",
    "print(f\"  Pulados:          {SKIPPED}\")\n",
    "print(f\"  Taxa de sucesso:  {pass_rate:.1f}%\")\n",
    "print(f\"\")\n",
    "\n",
    "# Barra visual\n",
    "bar_width = 40\n",
    "filled = int(bar_width * PASSED / total) if total > 0 else 0\n",
    "bar = '#' * filled + '-' * (bar_width - filled)\n",
    "print(f\"  [{bar}] {pass_rate:.1f}%\")\n",
    "print(f\"\")\n",
    "\n",
    "if FAILED == 0:\n",
    "    print(\"  RESULTADO: TODOS OS TESTES PASSARAM!\")\n",
    "    print(\"  O sistema unificado esta funcionando corretamente para os 3 modelos.\")\n",
    "else:\n",
    "    print(f\"  RESULTADO: {FAILED} TESTE(S) FALHARAM\")\n",
    "    print(f\"  Revise os itens marcados com FAIL acima.\")\n",
    "\n",
    "print(f\"\")\n",
    "print(f\"  Plataformas testadas:\")\n",
    "print(f\"    - Claude Code  (CLAUDE.md -> .agents/)\")\n",
    "print(f\"    - Codex CLI    (AGENTS.md -> .codex/ -> .agents/)\")\n",
    "print(f\"    - Antigravity  (GEMINI.md -> .agents/)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}